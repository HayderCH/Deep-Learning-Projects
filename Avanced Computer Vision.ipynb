{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/zLs5xSR6tUG6EOpOvM8p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Advanced deep learning for computer vision"],"metadata":{"id":"wfsKL2lBDeGj"}},{"cell_type":"markdown","source":["##Three essential computer vision tasks"],"metadata":{"id":"Hfs7YfKmDZIL"}},{"cell_type":"markdown","source":["In general, there are three essential computer vision tasks you\n","need to know about:\n"," Image classification—Where the goal is to assign one or more labels to an image.\n","It may be either single-label classification (an image can only be in one category, excluding the others), or multi-label classification (tagging all categories\n","that an image belongs to, as seen in figure 9.1). For example, when you search\n","for a keyword on the Google Photos app, behind the scenes you’re querying a\n","very large multilabel classification model—one with over 20,000 different classes,\n","trained on millions of images.\n"," Image segmentation—Where the goal is to “segment” or “partition” an image into\n","different areas, with each area usually representing a category (as seen in figure 9.1). For instance, when Zoom or Google Meet diplays a custom background behind you in a video call, it’s using an image segmentation model to\n","tell your face apart from what’s behind it, at pixel precision.\n"," Object detection—Where the goal is to draw rectangles (called bounding boxes)\n","around objects of interest in an image, and associate each rectangle with a class.\n","A self-driving car could use an object-detection model to monitor cars, pedestrians, and signs in view of its cameras, for instance."],"metadata":{"id":"8werxYtFDUq8"}},{"cell_type":"markdown","source":["There are two different flavors of image segmentation that you should know about:\n"," Semantic segmentation, where each pixel is independently classified into a semantic category, like “cat.” If there are two cats in the image, the corresponding pixels are all mapped to the same generic “cat” category (see figure 9.2).\n"," Instance segmentation, which seeks not only to classify image pixels by category,\n","but also to parse out individual object instances. In an image with two cats in it,\n","instance segmentation would treat “cat 1” and “cat 2” as two separate classes of\n","pixels (see figure 9.2)"],"metadata":{"id":"npd-8XZ6Wrvf"}},{"cell_type":"markdown","source":["A segmentation mask is\n","the image-segmentation equivalent of a label: it’s an image the same size as the input\n","image, with a single color channel where each integer value corresponds to the class of the corresponding pixel in the input image. In our case, the pixels of our segmentation masks can take one of three integer values:\n"," 1 (foreground)\n"," 2 (background)\n"," 3 (contour)"],"metadata":{"id":"0cta1G7pXoAG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pv5ZT3-rAEuF"},"outputs":[],"source":[]}]}